# -*- coding: utf-8 -*-
"""Dissertation CNN Working.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zynuIu59H3tNmUy_YWTYIu6nTRCCXWPQ
"""

# Commented out IPython magic to ensure Python compatibility.
from __future__ import absolute_import, division, print_function, unicode_literals

try:
  # %tensorflow_version only exists in Colab.
#   %tensorflow_version 2.x
except Exception:
  pass
import tensorflow as tf

from tensorflow.keras import datasets, layers, models
import matplotlib.pyplot as plt
import numpy as np
from keras.preprocessing.image import load_img
from keras.preprocessing.image import img_to_array
from keras.preprocessing.image import array_to_img
import seaborn as sn
import time

# Download CIFAR-10 dataset from Keras
# Data comes already split between training and testing
# Data split: 50000 Training images | 10000 Testing images

(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()

# Normalise pixel values between 0 and 1
train_images, test_images = train_images / 255.0, test_images / 255.0

# CIFAR-10 contains 10 classes
# Define label names
label_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',
               'dog', 'frog', 'horse', 'ship', 'truck']

# DEFINE FULLY CONNECTED NETWORKS

def fully1():
  model = models.Sequential()
  model.add(layers.Dense(64, input_shape=(32, 32, 3)))
  return model

def fully2():
  model = models.Sequential()
  model.add(layers.Dense(64, input_shape=(32, 32, 3)))
  model.add(layers.Dense(64, activation="relu"))
  return model

def fully3():
  model = models.Sequential()
  model.add(layers.Dense(64, input_shape=(32, 32, 3)))
  model.add(layers.Dense(64, activation="relu"))
  model.add(layers.Dense(64, activation="relu"))
  return model

def fully4():
  model = models.Sequential()
  model.add(layers.Dense(128, input_shape=(32, 32, 3)))
  return model

def fully5():
  model = models.Sequential()
  model.add(layers.Dense(64, input_shape = (32, 32, 3)))
  model.add(layers.Dropout(0.5))

  return model

def fully6():
  model = models.Sequential()
  model.add(layers.Dense(64, input_shape=(32, 32, 3)))
  model.add(layers.Dropout(0.5))
  model.add(layers.Dense(64, activation="relu"))
  return model

def fully7():
  model = models.Sequential()
  model.add(layers.Dense(64, input_shape=(32, 32, 3)))
  model.add(layers.Dropout(0.5))
  model.add(layers.Dense(64, activation="relu"))
  model.add(layers.Dropout(0.5))
  model.add(layers.Dense(64, activation="relu"))


  return model

def fully8():
  model = models.Sequential()
  model.add(layers.Dense(64, input_shape=(32, 32, 3)))
  model.add(layers.MaxPooling2D((2, 2)))
  model.add(layers.Dense(64, activation="relu"))
  model.add(layers.Dense(64, activation="relu"))
  model.add(layers.Dropout(0.5))

  return model

def fully9():
  model = models.Sequential()
  model.add(layers.Dense(64, input_shape=(32, 32, 3)))
  model.add(layers.MaxPooling2D((2, 2)))
  model.add(layers.Dense(64, activation="relu"))
  model.add(layers.Dropout(0.5))
  model.add(layers.Dense(64, activation="relu"))
  model.add(layers.Dense(32, activation="relu"))

  return model  



def fully10():
  model = models.Sequential()
  model.add(layers.Dense(64, input_shape=(32, 32, 3)))
  model.add(layers.MaxPooling2D((2, 2)))
  model.add(layers.Dense(64, activation="relu"))
  model.add(layers.Dropout(0.5))

  return model


"""
DEFINING CONVOLUTIONAL NETWORK MODELS
"""

def conv1():
  model = models.Sequential()
  # cifar data is 32x32 with 3 colour channels (RGB)
  model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))
  # pooling dimensions represent the scale to downscale the inputs to a smaller feature map
  model.add(layers.MaxPooling2D((2, 2)))

  return model

def conv2():
  model = models.Sequential()
  model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))
  model.add(layers.MaxPooling2D((2, 2)))
  model.add(layers.Conv2D(64, (3, 3), activation='relu'))

  return model


def conv3():
  model = models.Sequential()
  model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))
  model.add(layers.Conv2D(64, (3, 3), activation='relu'))
  model.add(layers.Conv2D(64, (3, 3), activation='relu'))
  model.add(layers.Conv2D(64, (3, 3), activation='relu'))

  return model

def conv4():
  # Conv -> MaxPool -> Conv -> MaxPool -> Conv -> Conv -> MaxPool
  model = models.Sequential()
  model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))
  model.add(layers.MaxPooling2D((2, 2)))
  model.add(layers.Conv2D(64, (3, 3), activation='relu'))
  model.add(layers.MaxPooling2D((2, 2)))
  model.add(layers.Conv2D(64, (3, 3), activation='relu'))
  model.add(layers.Conv2D(64, (3, 3), activation='relu'))
  model.add(layers.MaxPooling2D((2, 2)))

  return model


def conv5():
  model = models.Sequential()
  model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3)))
  model.add(layers.Conv2D(64, (3, 3), activation='relu'))
  model.add(layers.MaxPooling2D((2, 2)))
  model.add(layers.Conv2D(64, (3, 3), activation='relu'))
  model.add(layers.Conv2D(64, (3, 3), activation='relu'))
  model.add(layers.Conv2D(64, (3, 3), activation='relu'))
  model.add(layers.MaxPooling2D((2, 2)))

  return model

def conv6():
  model = models.Sequential()
  model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3)))
  model.add(layers.Conv2D(64, (3, 3), activation='relu'))
  model.add(layers.MaxPooling2D((2, 2)))
  model.add(layers.Conv2D(96, (3, 3), activation='relu'))
  model.add(layers.Conv2D(64, (3, 3), activation='relu'))
  model.add(layers.Conv2D(64, (3, 3), activation='relu'))
  model.add(layers.MaxPooling2D((2, 2)))

  return model

def conv7():
  model = models.Sequential()
  model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3)))
  model.add(layers.Conv2D(64, (3, 3), activation='relu'))
  model.add(layers.MaxPooling2D((2, 2)))
  model.add(layers.Conv2D(96, (3, 3), activation='relu'))
  model.add(layers.Conv2D(96, (3, 3), activation='relu'))
  model.add(layers.Conv2D(96, (3, 3), activation='relu'))
  model.add(layers.MaxPooling2D((2, 2)))

  return model


def conv8():
  model = models.Sequential()
  model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3)))
  model.add(layers.Conv2D(64, (3, 3), activation='relu'))
  model.add(layers.MaxPooling2D((2, 2)))
  model.add(layers.Conv2D(64, (3, 3), activation='relu'))
  model.add(layers.Conv2D(64, (3, 3), activation='relu'))
  model.add(layers.Conv2D(64, (3, 3), activation='relu'))
  model.add(layers.MaxPooling2D((2, 2)))
  model.add(layers.Conv2D(64, (3, 3), activation='relu'))
  model.add(layers.MaxPooling2D((2, 2)))

  return model


def conv9():
  model = models.Sequential()
  model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))
  model.add(layers.MaxPooling2D((2, 2)))
  model.add(layers.Conv2D(64, (3, 3), activation='relu'))
  model.add(layers.Conv2D(64, (3, 3), activation='relu'))
  model.add(layers.Conv2D(64, (3, 3), activation='relu'))

  return model


def conv10():
  model = models.Sequential()
  model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))
  model.add(layers.MaxPooling2D((2, 2)))
  model.add(layers.Conv2D(64, (3, 3), activation='relu'))
  model.add(layers.Conv2D(128, (3, 3), activation='relu'))
  model.add(layers.Conv2D(256, (3, 3), activation='relu'))
  model.add(layers.MaxPooling2D((2, 2)))

  return model

# Flatten layers
# create 10 output channels
# Mimics the final fully connected layer of a network

def flattenLayers(model):
  model.add(layers.Flatten())
  model.add(layers.Dense(64, activation="relu"))
  model.add(layers.Dense(10, activation="softmax"))

  return model

# Build and train the model 


def compileNet(net):
  """
  - takes in a flattened network as an input
  - returns a compiled 
  """
  # compile model https://www.tensorflow.org/guide/keras/functional  
  net.compile(optimizer='adam',
                loss='sparse_categorical_crossentropy',
                metrics=['accuracy'])
  return net

def getNetworkHistory(compiled_network):
  """
  - takes a compiled network as an input
  - returns network history from evaluating performance on training and test 
    data sets
  """
  # fit model
  network_history = convNet.fit(train_images, train_labels, epochs=epochs, 
                      validation_data=(test_images, test_labels))
  return network_history

def plotGraph(history):
  plt.plot(history.history['accuracy'], label='accuracy')
  plt.plot(history.history['val_accuracy'], label = 'val_accuracy')
  plt.legend(loc='lower right')
  plt.xlabel('Epochs')
  plt.ylabel('Accuracy')

def getTestMetrics(trained_net):
  """
  - takes a compiled and trained network as input
  - prints test set evaluation metrics 
  """
  test_loss, test_acc = convNet.evaluate(test_images,  test_labels, verbose=2)
  print("Loss: ", test_loss)
  print("Accuracy: ", test_acc)
  
  # train_loss, train_acc = convNet.evaluate(train_images, train_labels, verbose=2)
  # print("Training loss", train_loss)
  # print("Training accuracy", train_acc)


def show_structure(flattened_net):
  flattened_net.summary()
  tf.keras.utils.plot_model(flattened_net, 'multi_input_and_output_model.png', show_shapes=False)

epochs = 30

# Enter the network to be used here
net = fully10()

# add the last fully connected layer
convNet = flattenLayers(net)

# display the networks structure as an iamge
show_structure(convNet)

# compile the network
compiled_net = compileNet(convNet)

# Train the network
# recording the training length in seconds
t_start = time.time()
network_history = getNetworkHistory(compiled_net)
t_end = time.time()

t_total = t_end - t_start
print("Elapsed time: ",t_total)

# Display performance metrics
plotGraph(network_history)
getTestMetrics(convNet)

# prediction

probability_model = tf.keras.Sequential([convNet, 
                                         tf.keras.layers.Softmax()])

predictions = probability_model.predict(test_images)


# define the size of the confusion matrix 
# and retrieve the respective number of predictions
preds = []
pred_size = 1000
for i in range(pred_size):
  preds.append(np.argmax(predictions[i]))

# produce a confusion matrix
conf_matrix = tf.math.confusion_matrix(preds, test_labels[:pred_size], num_classes=10)
sn.heatmap(conf_matrix, annot=True, cmap=sn.color_palette("Blues"))

def label_num_to_name(label_num):
  name = label_names[label_num]
  return name
  


def make_prediction(trained_network, img_num):
    probability_model = tf.keras.Sequential([convNet, 
                                         tf.keras.layers.Softmax()])
    predictions = probability_model.predict(test_images)
    

    # convert numpy array back to image
    img = array_to_img(test_images[img_num])

    # Prediction
    pred = np.argmax(predictions[img_num])
    pred_name = label_num_to_name(pred)
    

    # Truth
    truth_num = test_labels[img_num][0]
    truth_name = label_num_to_name(truth_num)

    print("Prediction: ", pred,  pred_name)
    print("Truth label: ", truth_num, truth_name)
    
    plt.figure(figsize=(1,1))
    plt.imshow(img)
    
    plt.show()
    

def multiple_predicts(trained_network, array_of_img_nums):
      probability_model = tf.keras.Sequential([convNet, 
                                          tf.keras.layers.Softmax()])
      predictions = probability_model.predict(test_images)
      
      
      for n in array_of_img_nums:
        # convert numpy array back to image
        img = array_to_img(test_images[n])

        # Prediction
        pred = np.argmax(predictions[n])
        pred_name = label_num_to_name(pred)

        # Truth
        truth_num = test_labels[n][0]
        truth_name = label_num_to_name(truth_num)
      
        plt.figure(figsize=(1,3))
        plt.imshow(img)
      
      plt.show()
    

make_prediction(convNet, 13)
make_prediction(convNet, 15)
make_prediction(convNet, 4)


# label_num_to_name(5)