# -*- coding: utf-8 -*-
"""Dissertation Postures.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1i_o__xezvxQ45DRb6Bwgit-ix2mjERbN
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
import os
import numpy as np
import time

from keras.preprocessing.image import load_img
from keras.preprocessing.image import img_to_array
from keras.preprocessing.image import array_to_img

from __future__ import absolute_import, division, print_function, unicode_literals

try:
  # %tensorflow_version only exists in Colab.
#   %tensorflow_version 2.x
except Exception:
  pass
import tensorflow as tf

from tensorflow.keras import datasets, layers, models
import matplotlib.pyplot as plt
import numpy as np


drive.mount('/content/drive')

!ls "/content/drive/My Drive/Datasets/refined posture dataset"

cwd = os.getcwd()

dataset_location = '/drive/My Drive/Datasets/refined posture dataset'
folder_num = 1
data = cwd + dataset_location + '/postures'
current_folder = data + str(folder_num)

# load all bends

def load_and_convert(posture_type):
	posture_type = str(posture_type)
	np_data = []

	print("Loading and converting " + posture_type + "...\n")
	# iterate over all 'bend' folders
	for i in range(1,11): 
		current_folder = data + str(i) + '//' + posture_type	
		# get file names in folder
		folder = os.listdir(current_folder)

		# load and convert each image to numpy array
		for image in folder:
			img = load_img(current_folder + '//' + image)

			# convert to numpy array
			img_array = img_to_array(img)
			np_data.append(img_array)
			
	return np_data

start = time.time()
all_bends = load_and_convert('bend')
all_lie = load_and_convert('lie')
all_sit = load_and_convert('sit')
all_stand = load_and_convert('stand')
end = time.time()
print(end - start)

# Time taken: 713.5104157924652

label_names = ['bend', 'lie', 'sit', 'stand']

all_images = []
all_images.extend(all_bends)
all_images.extend(all_lie)
all_images.extend(all_sit)
all_images.extend(all_stand)
print(len(all_images))

# return a list of label names of length of the 
# given posture array
def createLabels(lbl_name, posture_arr):
  label = []
  for i in range(len(posture_arr)):
    label.append(lbl_name)
  return label

# generate labels arrays of the correct length
bend_labels = createLabels(0, all_bends)
lie_labels = createLabels(1, all_lie)
sit_labels = createLabels(2, all_sit)
stand_labels = createLabels(3, all_stand)

# add all lebels to a single array
labels = []
labels.extend(bend_labels)
labels.extend(lie_labels)
labels.extend(sit_labels)
labels.extend(stand_labels)

from sklearn.model_selection import train_test_split

# convert image array to a numpy array
all_images = np.asarray(all_images)

# convert label array to a numpy array
labels = np.asarray(labels)

# reshape label array so it can be split using train_test_split
l = np.reshape(labels, (len(labels),1))

# Split data
train_images, test_images, train_labels, test_labels = train_test_split(all_images, l, test_size = 0.30)

# DEFINE FULLY CONNECTED NETWORKS

def fully1():
  model = models.Sequential()
  model.add(layers.Dense(64, input_shape=(30, 30, 3)))
  return model

def fully2():
  model = models.Sequential()
  model.add(layers.Dense(64, input_shape=(30, 30, 3)))
  model.add(layers.Dense(64, input_shape=(30, 30, 3)))
  return model

def fully3():
  model = models.Sequential()
  model.add(layers.Dense(64, input_shape=(30, 30, 3)))
  model.add(layers.Dense(64, input_shape=(30, 30, 3)))
  model.add(layers.Dense(64, input_shape=(30, 30, 3)))

  return model

def fully4():
  model = models.Sequential()
  model.add(layers.Dense(128, input_shape=(30, 30, 3)))
  return model

def fully5():
  model = models.Sequential()
  model.add(layers.Dense(64, input_shape = (30, 30, 3)))
  model.add(layers.Dropout(0.5))

  return model

def fully6():
  model = models.Sequential()
  model.add(layers.Dense(64, input_shape=(30, 30, 3)))
  model.add(layers.Dropout(0.5))
  model.add(layers.Dense(64, input_shape=(30, 30, 3)))
  return model

def fully7():
  model = models.Sequential()
  model.add(layers.Dense(64, input_shape=(30, 30, 3)))
  model.add(layers.Dropout(0.5))
  model.add(layers.Dense(64, input_shape=(30, 30, 3)))
  model.add(layers.Dropout(0.5))
  model.add(layers.Dense(64, input_shape=(30, 30, 3)))


  return model

def fully8():
  model = models.Sequential()
  model.add(layers.Dense(64, input_shape=(30, 30, 3)))
  model.add(layers.MaxPooling2D((2, 2)))
  model.add(layers.Dense(64, activation="relu"))
  model.add(layers.Dense(64, activation="relu"))
  model.add(layers.Dropout(0.5))

  return model

def fully9():
  model = models.Sequential()
  model.add(layers.Dense(64, input_shape=(30, 30, 3)))
  model.add(layers.MaxPooling2D((2, 2)))
  model.add(layers.Dense(64, activation="relu"))
  model.add(layers.Dropout(0.5))
  model.add(layers.Dense(64, activation="relu"))
  model.add(layers.Dense(32, activation="relu"))

  return model  



def fully10():
  model = models.Sequential()
  model.add(layers.Dense(64, input_shape=(30, 30, 3)))
  model.add(layers.MaxPooling2D((2, 2)))
  model.add(layers.Dense(64, activation="relu"))
  model.add(layers.Dropout(0.5))

  return model


"""
DEFINING CONVOLUTIONAL NETWORK MODELS
"""

def conv1():
  model = models.Sequential()
  model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(30, 30, 3)))
  # pooling dimensions represent the scale to downscale the inputs to a smaller feature map
  model.add(layers.MaxPooling2D((2, 2)))

  return model

def conv2():
  model = models.Sequential()
  model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(30, 30, 3)))
  model.add(layers.MaxPooling2D((2, 2)))
  model.add(layers.Conv2D(64, (3, 3), activation='relu'))

  return model


def conv3():
  model = models.Sequential()
  model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(30, 30, 3)))
  model.add(layers.Conv2D(64, (3, 3), activation='relu'))
  model.add(layers.Conv2D(64, (3, 3), activation='relu'))
  model.add(layers.Conv2D(64, (3, 3), activation='relu'))

  return model

def conv4():
  # Conv -> MaxPool -> Conv -> MaxPool -> Conv -> Conv -> MaxPool
  model = models.Sequential()
  model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(30, 30, 3)))
  model.add(layers.MaxPooling2D((2, 2)))
  model.add(layers.Conv2D(64, (3, 3), activation='relu'))
  model.add(layers.MaxPooling2D((2, 2)))
  model.add(layers.Conv2D(64, (3, 3), activation='relu'))
  model.add(layers.Conv2D(64, (3, 3), activation='relu'))
  model.add(layers.MaxPooling2D((2, 2)))

  return model


def conv5():
  model = models.Sequential()
  model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(30,30,3)))
  model.add(layers.Conv2D(64, (3, 3), activation='relu'))
  model.add(layers.MaxPooling2D((2, 2)))
  model.add(layers.Conv2D(64, (3, 3), activation='relu'))
  model.add(layers.Conv2D(64, (3, 3), activation='relu'))
  model.add(layers.Conv2D(64, (3, 3), activation='relu'))
  model.add(layers.MaxPooling2D((2, 2)))

  return model

def conv6():
  model = models.Sequential()
  model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(30,30,3)))
  model.add(layers.Conv2D(64, (3, 3), activation='relu'))
  model.add(layers.MaxPooling2D((2, 2)))
  model.add(layers.Conv2D(96, (3, 3), activation='relu'))
  model.add(layers.Conv2D(64, (3, 3), activation='relu'))
  model.add(layers.Conv2D(64, (3, 3), activation='relu'))
  model.add(layers.MaxPooling2D((2, 2)))

  return model

def conv7():
  model = models.Sequential()
  model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(30,30,3)))
  model.add(layers.Conv2D(64, (3, 3), activation='relu'))
  model.add(layers.MaxPooling2D((2, 2)))
  model.add(layers.Conv2D(96, (3, 3), activation='relu'))
  model.add(layers.Conv2D(96, (3, 3), activation='relu'))
  model.add(layers.Conv2D(96, (3, 3), activation='relu'))
  model.add(layers.MaxPooling2D((2, 2)))

  return model


def conv8():
  model = models.Sequential()
  model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(30,30,3)))
  model.add(layers.Conv2D(64, (3, 3), activation='relu'))
  model.add(layers.MaxPooling2D((2, 2)))
  model.add(layers.Conv2D(64, (3, 3), activation='relu'))
  model.add(layers.Conv2D(64, (3, 3), activation='relu'))
  model.add(layers.Conv2D(64, (3, 3), activation='relu'))
  model.add(layers.MaxPooling2D((2, 2)))
  model.add(layers.Conv2D(64, (3, 3), activation='relu'))

  return model


def conv9():
  model = models.Sequential()
  model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(30, 30, 3)))
  model.add(layers.MaxPooling2D((2, 2)))
  model.add(layers.Conv2D(64, (3, 3), activation='relu'))
  model.add(layers.Conv2D(64, (3, 3), activation='relu'))
  model.add(layers.Conv2D(64, (3, 3), activation='relu'))

  return model

def conv10():
  model = models.Sequential()
  model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(30, 30, 3)))
  model.add(layers.MaxPooling2D((2, 2)))
  model.add(layers.Conv2D(64, (3, 3), activation='relu'))
  model.add(layers.Conv2D(32, (3, 3), activation='relu'))


  return model

# Flatten layers
# create 4 output channels
# Mimics the final fully connected layer of a network

def flattenLayers(model):
  model.add(layers.Flatten())
  model.add(layers.Dense(64, activation="relu"))
  model.add(layers.Dense(4, activation="softmax"))

  return model

# Build and train the model 


def compileNet(net):
  """
  - takes in a flattened network as an input
  - returns a compiled 
  """
  # compile model https://www.tensorflow.org/guide/keras/functional 
  net.compile(optimizer='adam',
                loss='sparse_categorical_crossentropy',
                metrics=['accuracy'])
  return net

def getNetworkHistory(compiled_network):
  """
  - takes a compiled network as an input
  - returns network history from evaluating performance on training and test 
    data sets
  """
  # fit model
  network_history = convNet.fit(train_images, train_labels, epochs=epochs, 
                      validation_data=(test_images, test_labels))
  return network_history

def plotGraph(history):
  plt.plot(history.history['accuracy'], label='accuracy')
  plt.plot(history.history['val_accuracy'], label = 'val_accuracy')
  plt.xlabel('Epochs')
  plt.ylabel('Accuracy')

def getTestMetrics(trained_net):
  """
  - takes a compiled and trained network as input
  - prints test set evaluation metrics 
  """
  test_loss, test_acc = convNet.evaluate(test_images,  test_labels, verbose=2)
  print("Loss: ", test_loss)
  print("Accuracy: ", test_acc)
  
  # train_loss, train_acc = convNet.evaluate(train_images, train_labels, verbose=2)
  # print("Training loss", train_loss)
  # print("Training accuracy", train_acc)


def show_structure(flattened_net):
  flattened_net.summary()
  tf.keras.utils.plot_model(flattened_net, 'multi_input_and_output_model.png', show_shapes=False)

import time
epochs = 30

# Enter the network to be used here
net = fully10()

# add the last fully connected layer
convNet = flattenLayers(net)

# display the networks structure as an iamge
show_structure(convNet)

# compile the network
compiled_net = compileNet(convNet)

# Train the network
# recording the training length in seconds
t_start = time.time()
network_history = getNetworkHistory(compiled_net)
t_end = time.time()

t_total = t_end - t_start
print("Elapsed time: ",t_total)

# Display performance metrics
plotGraph(network_history)
getTestMetrics(convNet)

print(np.shape(train_images))
print(np.shape(train_labels))
print(np.shape(test_images))
print(np.shape(test_labels))

def label_num_to_name(label_num):
  name = label_names[label_num]
  return name
  

  

def make_prediction(trained_network, img_num):
    probability_model = tf.keras.Sequential([convNet, 
                                         tf.keras.layers.Softmax()])
    predictions = probability_model.predict(test_images)
    

    # convert numpy array back to image
    img = array_to_img(test_images[img_num])

    # Prediction
    pred = np.argmax(predictions[img_num])
    pred_name = label_num_to_name(pred)
    

    # Truth
    truth_num = test_labels[img_num][0]
    truth_name = label_num_to_name(truth_num)

    print("Prediction: ", pred,  pred_name)
    print("Truth label: ", truth_num, truth_name)
    
    plt.figure(figsize=(1,1))
    plt.imshow(img)
    
    plt.show()
    

def multiple_predicts(trained_network, array_of_img_nums):
      probability_model = tf.keras.Sequential([convNet, 
                                          tf.keras.layers.Softmax()])
      predictions = probability_model.predict(test_images)
      
      
      for n in array_of_img_nums:
        # convert numpy array back to image
        img = array_to_img(test_images[n])

        # Prediction
        pred = np.argmax(predictions[n])
        pred_name = label_num_to_name(pred)

        # Truth
        truth_num = test_labels[n][0]
        truth_name = label_num_to_name(truth_num)
      
        plt.figure(figsize=(1,3))
        plt.imshow(img)
      
      plt.show()
    

make_prediction(convNet, 13)
make_prediction(convNet, 15)
make_prediction(convNet, 4)


# label_num_to_name(5)